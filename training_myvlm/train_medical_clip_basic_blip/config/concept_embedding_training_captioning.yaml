concept_name: hyoidbone
concept_identifier: sks            # For people, this should be a short name such as Bob or Anna
concept_type: OBJECT               # Can also be PERSON
vlm_type: BLIP2
personalization_task: CAPTIONING   # For BLIP-2, we only focus on CAPTIONING, but VQA is also possible
output_root: /home/user_7734/training_myvlm/train_medical_clip_basic_blip/output_concept_embedding_training
data_root: /home/user_7734/training_myvlm/train_medical_clip_basic_blip/data/pos_hyoidbone
concept_head_path: /home/user_7734/training_myvlm/train_medical_clip_basic_blip/trained_concept_head
threshold: 0.5
optimization_steps: 100
learning_rate: 1.0
batch_size: 4
reg_lambda: 0.04
save_interval: 25
val_interval: 25
seed: 42           # If concept is an object, this should be the same seed that was used for training the concept heads
device: cuda
torch_dtype: bfloat32
