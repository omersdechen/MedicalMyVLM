concept_name: my_cat
concept_identifier: sks            # For people, this should be a short name such as Bob or Anna
concept_type: OBJECT               # Can also be PERSON
vlm_type: BLIP2
personalization_task: CAPTIONING   # For BLIP-2, we only focus on CAPTIONING, but VQA is also possible
output_root: /home/user_7734/omer/try_train_my_cat/embed_output
data_root: /home/user_7734/omer/try_train_my_cat
concept_head_path: /home/user_7734/omer/try_train_my_cat/concept_head_trained     # Can be ignored if working with people
threshold: 0.5                                # For people, this should be 0.675
optimization_steps: 100
learning_rate: 1.0
batch_size: 4
reg_lambda: 0.04
save_interval: 25
val_interval: 25
seed: 42           # If concept is an object, this should be the same seed that was used for training the concept heads
device: cuda
torch_dtype: bfloat16
